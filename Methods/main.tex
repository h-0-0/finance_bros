\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}


% PACKAGES 
\usepackage{amssymb}
\usepackage[dvipsnames]{xcolor}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{bbm}
\usepackage{array}
\usepackage[
backend=biber,
sorting=anyt,
defernumbers=true,
style=authoryear,
natbib
]{biblatex}
\addbibresource{references.bib}
\setlength\bibitemsep{\baselineskip}

% FORMATTING
\setlength{\parskip}{0.7em}
\setlength{\parindent}{0em}
\usepackage[left = 2.5cm , right = 2.5cm, bottom = 2.7cm, top = 2.7cm]{geometry}
\usepackage{titling}
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

%COMMANDS
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\newcommand{\argminun}{\underset{\mathbf{w}}{\argmin}}
\newcommand{\argmaxun}{\underset{\mathbf{w}}{\argmax}}
\newcommand{\bxi}{\mathbf{x}_i}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bphi}{\boldsymbol\phi}
\newcommand*{\vertbar}{\rule[-1ex]{0.5pt}{2.5ex}}
\newcommand*{\horzbar}{\rule[.5ex]{2.5ex}{0.5pt}}

\title{\vspace{-2cm}Title}
\author{Authors}
\date{\vspace{-5ex}}
\begin{document}
 
\maketitle

\begin{abstract}
In this document we will be using support vector machine (SVM) for financial time series forecasting of the value of the digital currency, Bitcoin. We will create several prediction models using SVM that will use different asset price data, which will be compared performance against each other to determine which assets are most associated to accurate predictions of Bitcoin.  

\end{abstract}

\section{Introduction}
In this paper, we propose using support vector regression (SVR) to forecast the value of bitcoin using data from other cryptocurrencies and stocks. SVR is a powerful machine learning technique that has been successfully applied to a wide range of regression problems. By training an SVR model on a dataset of past cryptocurrency and stock values, we aim to build a model that can accurately predict the future value of bitcoin. In the following sections, we will describe the dataset and feature engineering steps taken to prepare the data for modeling, the SVR model training and evaluation process, and present the results and analysis of our forecasting approach.

\section{Forecasting Methodology}
We will denote our set of predictors by the matrix $\bX$, where the $i$th row is denoted by $\bx_i$, and we let $Y$ denote the vector of outcome observations. 


\subsection{Support Vector Regression (SVR)}
For Support Vector Regression (SVR) the goal is to find a function that estimates the target variable as a linear combination of the input variables, while minimizing the error between the predictions and the true values.

The optimization problem for SVM regression can be formulated as follows:
minimize $1/2||w||^2 + C \sum \xi_i$
subject to $y_i - (w^T x_i + b) <= \epsilon + \xi_i$ , for all $i = 1, ..., n$ and $\xi_i >= 0$
where $w$ is the weight vector, $b$ is the bias, $C$ is a regularization parameter, $\epsilon$ is the margin width and $\xi_i$ are the error/slack variables. The vector $x_i$ and $y_i$ represent the input and output variables, respectively.

The goal is to find the weight vector, $w$ and bias $b$ that minimizes the objective function. To do this, a technique such as quadratic programming should be used. In addition, the constraints ensure that the difference between the predicted and true values of the target variable is at most $\epsilon + \xi_i$ for all instances. This allows for a certain degree of error, controlled by the parameter $\epsilon$, but penalizes larger errors through the term $C * \xi_i$.

It's important to mention that in this case, the prediction is a real value instead of a class label, so it's possible to have an error term, unlike in SVM classification. The cost function is a trade-off between a margin of tolerance to errors and a regularization term that avoids over-fitting. The parameter $C$ determines this trade-off. If $C$ is large, it puts more weight on the errors and tries to minimize them, while if $C$ is small it gives more importance to the regularization term which tries to keep the model simple.

\citet{trafalisSVM}

\newpage

\citet{trafalisSVM}

\newpage
\input{Methods/appendix.tex}

\section{Bibliography}
\printbibliography

\end{document}


